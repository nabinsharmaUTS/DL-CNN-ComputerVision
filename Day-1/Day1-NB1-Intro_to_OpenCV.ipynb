{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["4SSSaCJCSGlA"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QVeR7LnaLh5E"},"source":["# **Deep Learning and CNN for Computer Vision, Hokkaido University**\n","\n","## Day 1, Notebook -1: Introduction to OpenCV\n","\n","Welcome to Day 1 hands on session. This is a warmup session for OpenCV Library. We will be learning the following:\n","1.\tReading and Displaying Images\n","2.\tWriting Images to disk\n","3.\tPlotting images\n","4.\tProcessing RBG Images: splitting in three channels\n","5.  Basic image processing: Thresholding, Edge detection, etc.\n","\n","So lets get started!\n"]},{"cell_type":"markdown","metadata":{"id":"1ETQvHmiSGkx"},"source":["## Introduction to Image Processing in OpenCV\n","\n","OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc.\n","It has C++, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS. OpenCV leans mostly towards real-time vision applications and takes advantage of MMX and SSE instructions when available. A full-featured CUDAand OpenCL interfaces are being actively developed right now.\n","\n","Source: https://opencv.org/about.html\n","\n","## What is image & pixel?\n","\n","Computer considers an image as a matrix; each value in the matrix represents a single pixel. A pixel is a basic building block of an image. A pixel has a value between 0 and 255, whereas the value of 0 represents complete black and 255 represent complete white. The shade of the color varies between 0 and 255 to show various. Similarly, a pixel in RGB image is represented by tuple such as (red, green, blue)\n","\n","What is the color of the image having a value of (255,255,255)?   \n","\n"]},{"cell_type":"code","metadata":{"id":"TpdsmMaOSGk2"},"source":["# import the packages required\n","# CV2 is the package used for image processing\n","import cv2\n","# matplotlib is plotting library used for displaying images\n","import matplotlib.pyplot as plt\n","# Numpy is for matrix computation\n","import numpy as np\n","from IPython.display import display, HTML, clear_output\n","print(cv2.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBxE_7siTOPl"},"source":["## Connecting to Google Drive"]},{"cell_type":"code","metadata":{"id":"m0EvivP9TUVs"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81u9WB8KqTiB"},"source":["### Change directory to Day-1"]},{"cell_type":"code","metadata":{"id":"KAnxgrbrUP_W"},"source":["cd /content/gdrive/MyDrive/Hokkaido Uni DL/Day-1"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"Qy4DmSyl5f8i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZKFqJ0NXqM8R"},"source":["### Unzip the dataset file"]},{"cell_type":"code","metadata":{"id":"SQjx0d1jpots"},"source":["!unzip dataset.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jKilYOFBqjyc"},"source":["### Change the Directory to the dataset folder"]},{"cell_type":"code","metadata":{"id":"d4JOzDhAqgRD"},"source":["cd dataset/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SSSaCJCSGlA"},"source":["### 1. Reading an Image using imread() function\n","load the image\n","img= cv2.imread(path to image)"]},{"cell_type":"code","metadata":{"id":"DGmyM3dlSGlE"},"source":["img=cv2.imread('lena.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3Nc0rVPSGlK"},"source":["# Check is the image was loaded successfully\n","if img is None:\n","    print('Image not found')\n","else:\n","    print('Image Loaded')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TrjYyhBuSGlS"},"source":["### 2. Display information about an image\n","\n","Images are read as a numpy array. The shape method gives us essential information about image such as size etc.\n","\n"]},{"cell_type":"code","metadata":{"id":"02SCvns6SGlU"},"source":["print(img.shape)\n","print(img.dtype)\n","print(img.shape[0])\n","print(img.shape[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ReAZ38vDSGla"},"source":["### 3. Display/show image"]},{"cell_type":"code","metadata":{"id":"RLV_gfF9SGlc"},"source":["# plt read images in RGB format while CV2 reads images in BGR format.\n","plt.imshow(img)\n","plt.show()\n","# convert BGR to RGB\n","img_rgb=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","plt.imshow(img_rgb)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7Pde7j6uaIg"},"source":["# can we grab a pixel value at [0,0]?\n","\n","print(img[0,0])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mdbjmu0tSGln"},"source":["### 4. Save image to the disk\n","\n","In this example an image is read from folder and converted to gray-level image and finally saved to the disk as a new image using\n","\n","#### cv2.imwrite(\"image name\", image)."]},{"cell_type":"code","metadata":{"id":"TIcRJedCSGlt"},"source":["input_image = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # input_image: 2-dim array\n","plt.imshow(input_image, cmap='gray')  # Make sure that the plot is drawn in grayscale\n","cv2.imwrite('Saved_image.png',input_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"npZ2XfS7-2OY"},"source":["\n","### 5. Plotting images: Subplot\n","\n","Subplot can be used to plot multiple plots in a grid of a given size.\n","\n","\n","**Format: plt.subplot(nrows, ncols, index)**\n"]},{"cell_type":"code","metadata":{"id":"7LLl01xESGl2"},"source":["ax1 = plt.subplot(1,3,1)\n","plt.title(\"RGB Image\")\n","plt.imshow(img_rgb)\n","\n","ax2 = plt.subplot(1,3,2)\n","plt.title(\"BGR Image\")\n","plt.imshow(img)\n","ax3=plt.subplot(1,3,3)\n","\n","plt.title(\"Gray Image\")\n","plt.imshow(input_image, cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s4g9xNTR_b1y"},"source":["### 6. Splitting an image into its channels\n","This example shows about splitting an image into channels. With the use of subplot, the original image and its corresponding channels are plotted.\n","\n","**What do the plots show?**"]},{"cell_type":"code","source":["img"],"metadata":{"id":"xa-wsTeiIqcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bJPBsEENSGmA"},"source":["# Displaying just single channel in 2D\n","img=cv2.imread('lena.png')\n","plt.figure(figsize=(15,15))\n","ax1 = plt.subplot(1,4,1)\n","plt.title(\"Original Image in BGR\")\n","plt.imshow(img)\n","\n","ax2 = plt.subplot(1,4,2)\n","blue=img[:,:,0]\n","print(blue)\n","plt.title(\"Blue channel\")\n","plt.imshow(blue)\n","##\n","ax3=plt.subplot(1,4,3)\n","green=img[:,:,1]\n","plt.title(\"Green channel\")\n","plt.imshow(green)\n","##\n","ax4=plt.subplot(1,4,4)\n","red=img[:,:,2]\n","plt.title(\"Red channel\")\n","plt.imshow(red)\n","\n","\n","##############################################################################\n","# Create RGB images of each channel for better visualization\n","img_rg=cv2.imread('lena.png')\n","img_rg=cv2.cvtColor(img_rg, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(15,15))\n","ax5 = plt.subplot(1,4,1)\n","plt.title(\"Original Image in RGB\")\n","plt.imshow(img_rg)\n","\n","\n","b = img_rg.copy()\n","b[:, :, 1] = 0 # [[[R, 0, 0], ..., ..., ], [.[R,G,B]..], [...]]\n","b[:, :, 2] = 0\n","ax5 = plt.subplot(1,4,2)\n","plt.title(\"Red channel\")\n","plt.imshow(b)\n","##\n","\n","g = img_rg.copy()\n","g[:, :, 0] = 0\n","g[:, :, 2] = 0\n","ax7=plt.subplot(1,4,3)\n","plt.title(\"Green channel\")\n","plt.imshow(g)\n","##\n","r = img_rg.copy()\n","r[:, :, 0] = 0\n","r[:, :, 1] = 0\n","ax8=plt.subplot(1,4,4)\n","plt.title(\"Blue channel\")\n","plt.imshow(r)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbsfR-EVSGmH"},"source":["zeros = np.zeros(img_rg.shape[:2], dtype = \"uint8\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zeros"],"metadata":{"id":"QQokURPNKGQF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Whi799mSGmM"},"source":["### **Task:**\n","\n","**Read test image from the folder and separate its channels into Red, Green, and Blue**"]},{"cell_type":"code","metadata":{"id":"KeIa3cAoSGmO"},"source":["\n","# Read test.jpeg from folder\n","img_test=cv2.imread('test.jpeg')\n","# Display the orginal image in BGR and RGB using the appropriate functions\n","zeros = np.zeros(img_test.shape[:2], dtype = \"uint8\")\n","\n","#split the image into channels using built-in function cv2.split\n","(B, G, R) = cv2.split(img_test)\n","\n","plt.imshow(img_test)\n","plt.show()\n","\n","# show the separate channels\n","\n","red=cv2.merge([zeros, zeros, np.subtract(R, 100)])\n","red=cv2.cvtColor(red, cv2.COLOR_BGR2RGB)\n","plt.imshow(red)\n","plt.show()\n","\n","green=cv2.merge([zeros, G, zeros])\n","plt.imshow(green)\n","plt.show()\n","\n","blu=cv2.merge([B, zeros, zeros])\n","blu=cv2.cvtColor(blu, cv2.COLOR_BGR2RGB)\n","plt.imshow(blu)\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ifs9ak7NSGmf"},"source":["### 7. Thresholding - Binarization\n","\n","\n","In simple thresholding example, a manual value of threshold T is set to binarize the image. This pixel values greater than T are set to 255 while values less than T is set to 0. The threshold value is considered using a trial and error method."]},{"cell_type":"code","metadata":{"id":"Ths2uzriSGmh"},"source":["# 1 Read in image\n","\n","coins = cv2.imread('coins1.jpg')\n","\n","# 2 Convert RGB to Gray-level\n","coins_gray = cv2.cvtColor(coins, cv2.COLOR_BGR2GRAY)\n","\n","# preprocessing the image with GaussianBlur\n","coins_preprocessed = cv2.GaussianBlur(coins_gray, (5, 5), 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Da_YOjOiSGmm"},"source":["plt.imshow(coins, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFu-wNV8SGmu"},"source":["plt.hist(coins.ravel(),256,[0,256]);\n","#plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0WPo6JxPb1rs"},"source":["### Command for thresholding (Manual Thresholding)\n","\n","**cv2.threshold(img,127,255,cv2.THRESH_BINARY)** where\n","\n","1.   First argument is img: which is gray-scale image\n","2.   Second argument is T (Threshold value)\n","3.  Third argument Third argument is the maxVal which\n","represents the value to be given if pixel value is more than the threshold value."]},{"cell_type":"code","metadata":{"id":"uLX_8LHMSGm_"},"source":[" (T, thresh) = cv2.threshold(coins_gray, 150, 255, cv2.THRESH_BINARY)\n","plt.imshow(thresh, cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BbcE4KCin7Jk"},"source":["### Automatic Thresholding\n","Otsu method is the way of automatic thresholding, where threshold value T is optimally found by the Otsu."]},{"cell_type":"code","metadata":{"id":"WWsnioKDBZFx"},"source":["\n","(T, threshotsu) = cv2.threshold(coins_gray, 0, 255, cv2.THRESH_OTSU)\n","print(\"Optimal threshold value: \", T)\n","plt.imshow(threshotsu, cmap='gray')\n","plt.imshow(thresh, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQhVQDUOKzme"},"source":["### 8. Edge detection in images\n","\n","Edge detection is the process of finding edges in images. The Sobel edge detector is one of the edge detection method, which actually uses two kernels: one for detecting horizontal changes in direction and the other for detecting vertical changes in direction.\n","\n","\n","gX = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=1, dy=0, 5)\n","\n","gY = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=0, dy=1,5)\n","\n","Both gX and gY are float type, for visualization it is required to convert it\n","\n","\n","**cv2.Sobel(original_image,ddepth,xorder,yorder,kernelsize)**"]},{"cell_type":"code","metadata":{"id":"HfXTNBrUK0Zl"},"source":["sobelx = cv2.Sobel(coins_gray,cv2.CV_64F,1,0,ksize=5)\n","gX = cv2.convertScaleAbs(sobelx)\n","plt.imshow(gX, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GpF5A5WTLJAe"},"source":["sobely = cv2.Sobel(coins_gray,cv2.CV_64F,0,1,ksize=5)\n","gY = cv2.convertScaleAbs(sobely)\n","plt.imshow(gY, cmap='gray')\n","plt.axis('off')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKkYATjvLfcZ"},"source":["sobelCombined = cv2.addWeighted(gX, 0.5, gY, 0.5, 0 )\n","plt.imshow(sobelCombined, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]}]}