{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mamiXm5pltDZ"},"source":["# **Deep Learning and CNN for Computer Vision, Hokkaido University**\n","\n","## Day 2, Notebook -2: Solving Overfitting Problem, and Regularization\n","\n","In this session you will be implementing regularization to avoid overfitting.\n","\n","So lets get started!\n","\n","## Tutorial:\n","Implementation of a  CNN architecture using Keras for classfication of Cats/Dogs Dataset from Kaggle.\n","\n","## Tasks for this week:\n","\n","1. Implementation of Neural Network for Dogs and Cats classification using Keras API.\n","2. Train and test model and identify overfitting.\n","3. Data augmentation and Drop outs\n"]},{"cell_type":"markdown","metadata":{"id":"CrgipiyWnlOF"},"source":["### Step 1: Import and required packages\n","\n","we will need tensorflow, numpy, os and keras\n"]},{"cell_type":"code","metadata":{"id":"cZzYq6qGXOUw"},"source":["import os\n","import zipfile\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"id":"xXy4rRpaO4OL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Install tensorflow==2.16.1 and restart the instance to use the downgraded version\n","!pip install tensorflow==2.16.1\n","import tensorflow as tf\n","tf.__version__\n"],"metadata":{"id":"B-uCFRRD4VO1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3xIRHR6JniK_"},"source":["### Step 2: Download the Cats & Dogs dataset"]},{"cell_type":"code","metadata":{"id":"wgsQ7VAJaKkS"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n","    -O /tmp/cats_and_dogs_filtered.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8wBdunUaLfg"},"source":["local_zip = '/tmp/cats_and_dogs_filtered.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp')\n","zip_ref.close()\n","\n","base_dir = '/tmp/cats_and_dogs_filtered'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","\n","# Directory with our training cat pictures\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","\n","# Directory with our training dog pictures\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","\n","# Directory with our validation cat pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","\n","# Directory with our validation dog pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZR9tma1foFEq"},"source":["### Step 3:  Design the CNN Architecture\n","\n","Design the following CNN architecture:\n","\n","<img src='http://drive.google.com/uc?export=view&id=1EAWFwp7T92q3Lm1ZrX9A2-wnvhfAfzSF' alt='Conv'>\n","\n","Input: $150 X 150 X 3$ image\n","\n","No. of filters, filter size:\n","- Conv1 : 32, 3x3\n","- Conv2 : 64, 3x3\n","- Conv3 : 128, 3x3\n","- Conv4 : 128, 3x3\n","\n","Activation function in CONV layer: Relu\n","\n","Pool: MaxPooling, 2x2\n","\n","Activation function in Output layer : sigmoid, 2 classes\n","\n","**Hint:** Use Conv2D(), MaxPooling2D(), Flatten(), and Dense()"]},{"cell_type":"code","metadata":{"id":"Ozg8aZL9afrX"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2d000jkgaj1I"},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(learning_rate=1e-4),\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vz9pRPjjomg5"},"source":["### Step 4:  Training CNN with ImageDataGenerator"]},{"cell_type":"code","metadata":{"id":"6NG8OyQ4asBu"},"source":["# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=20,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CbSRkelDa13h"},"source":["history = model.fit(\n","      train_generator,\n","      steps_per_epoch=100,  # 2000 images = batch_size * steps\n","      epochs=100,\n","      validation_data=validation_generator,\n","      validation_steps=50,  # 1000 images = batch_size * steps\n","      verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o35LXjMapnVB"},"source":["### Step 5:  Visualization of results and identification of overfitting"]},{"cell_type":"code","metadata":{"id":"EpCUC0x9a6-5"},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"34OgCm0qo7Se"},"source":["### Step 6:  Design of CNN for data augmentation"]},{"cell_type":"code","metadata":{"id":"XA9-5eRFcJ3t"},"source":["model_data_aug = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f9EF7vxHruuU"},"source":["### Step 7:  Using ImageDataGenerator for data augmentation"]},{"cell_type":"code","metadata":{"id":"xaCoYFuVr7cM"},"source":["# This code has changed. Now instead of the ImageGenerator just rescaling\n","# the image, we also rotate and do other operations\n","# Updated to do image augmentation\n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=20,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4MwocszcNwt"},"source":["model_data_aug.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(learning_rate=1e-4),\n","              metrics=['acc'])\n","\n","history = model_data_aug.fit(\n","      train_generator,\n","      steps_per_epoch=100,  # 2000 images = batch_size * steps\n","      epochs=100,\n","      validation_data=validation_generator,\n","      validation_steps=50,  # 1000 images = batch_size * steps\n","      verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eX78DKKOuSJa"},"source":["### Step 8:  Visualization the results"]},{"cell_type":"code","metadata":{"id":"Ykv7TW8vuCq9"},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JXc9Z3hxugOC"},"source":["### Step 9:  Using drop outs and data augmentation"]},{"cell_type":"code","source":["model_drop_out = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.5), #Adding Dropout\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model_drop_out.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(learning_rate=1e-4),\n","              metrics=['acc'])\n","\n","# This code has changed. Now instead of the ImageGenerator just rescaling\n","# the image, we also rotate and do other operations\n","# Updated to do image augmentation\n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,  # This is the source directory for training images\n","        target_size=(150, 150),  # All images will be resized to 150x150\n","        batch_size=20,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n","\n","history = model_drop_out.fit(\n","      train_generator,\n","      steps_per_epoch=100,  # 2000 images = batch_size * steps\n","      epochs=100,\n","      validation_data=validation_generator,\n","      validation_steps=50,  # 1000 images = batch_size * steps\n","      verbose=2)"],"metadata":{"id":"nlX5tNiAvcEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zENVDiiDu8G0"},"source":["### Step 10:  Visualization of results"]},{"cell_type":"code","metadata":{"id":"z1uqNTSxctyM"},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i65qqpZxTxVt"},"source":["## Optional:\n","\n","Try changing the Regularization to L1 and L2 and check output\n","\n","Hint:\n","\n","**L1** : tf.keras.regularizers.l1(l=0.01)\n","\n","**L2**: tf.keras.regularizers.l2(l=0.01)\n","\n","Reference: https://keras.io/regularizers/"]},{"cell_type":"code","metadata":{"id":"xw1VvdngTx8K"},"source":[],"execution_count":null,"outputs":[]}]}