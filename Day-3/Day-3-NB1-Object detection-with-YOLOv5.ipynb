{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"hide_input":false,"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"nav_menu":{"height":"122px","width":"252px"},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{"height":"758px","left":"0px","right":"1096px","top":"73px","width":"253px"},"toc_section_display":"block","toc_window_display":true},"colab":{"provenance":[],"collapsed_sections":["FOYg8WSFZ0Jl","K_dpwUYqIj5L","hoVEDxalH2Ly"]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"FOYg8WSFZ0Jl"},"source":["# **Deep Learning and CNN for Computer Vision, Hokkaido University**\n","\n","## Day 3, Notebook -1: Object Detection using YoloV5\n","\n","In this part of the session you will be exploring how to use the YOLO v5 object detector\n","\n","\n","So lets get started!\n","\n","\n","We will use the https://github.com/ultralytics/yolov5 repository for this tutorial\n","\n","Reference: https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"]},{"cell_type":"markdown","metadata":{"id":"YRfPs8W7JXa5"},"source":["# Step 1: Clone github repository"]},{"cell_type":"markdown","source":["#### **Connect to Google Drive**"],"metadata":{"id":"JnCIG7zCFt_i"}},{"cell_type":"code","metadata":{"id":"fe8Pk-N-TggN"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Custom Dataset Setup (We will use the Kangaroo dataset)**"],"metadata":{"id":"9WtcnZSZG0NY"}},{"cell_type":"code","source":["# Change path to you google drive location of the dataset as needed\n","!unzip '/content/gdrive/MyDrive/Hokkaido Uni DL/Day-3/yoloV5_kangaroo.zip'"],"metadata":{"id":"wCaDXvLZozjZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Clone the Github Repo (Default location /content/)**"],"metadata":{"id":"rS7VwEhDGCqV"}},{"cell_type":"code","source":["# By Default Cloned under /content/\n","!git clone https://github.com/ultralytics/yolov5"],"metadata":{"id":"72m3jBaxjb_a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install the required libraries"],"metadata":{"id":"b1o4IcqcGZpc"}},{"cell_type":"code","source":["%cd yolov5\n","from yolov5 import utils\n","#display = utils.notebook_init()  # checks Pytorch and GPU used. Need changes to correct path\n","!pip install -r requirements.txt"],"metadata":{"id":"ZSxIReiajdY3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Quick Reference on YAML**"],"metadata":{"id":"K_dpwUYqIj5L"}},{"cell_type":"markdown","source":["#### [**What is YAML?**](https://circleci.com/blog/what-is-yaml-a-beginner-s-guide/)\n","\n","YAML --> **Y**et **A**nother **M**arkup **L**anguage\n","\n","YAML is a digestible data serialization language often used to create configuration files with any programming language.\n","\n","Designed for human interaction, YAML is a strict superset of JSON, another data serialization language. But because itâ€™s a strict superset, it can do everything that JSON can and more. One major difference is that newlines and indentation actually mean something in YAML, as opposed to JSON, which uses brackets and braces.\n","\n","Reference and Source: https://circleci.com/blog/what-is-yaml-a-beginner-s-guide/"],"metadata":{"id":"hoVEDxalH2Ly"}},{"cell_type":"markdown","source":["# Step 2: Setup Training Configuration"],"metadata":{"id":"EPPXGoraGnYk"}},{"cell_type":"code","source":["#@title Setup Training YAML File\n","number_of_classes = 1 #@param {type:\"integer\"}\n","with open('new_train_yaml', 'w+') as file:\n","    file.write(\n","        f\"\"\"\n","        # parameters\n","        nc: {number_of_classes}  # number of classes\n","        depth_multiple: 0.33  # model depth multiple\n","        width_multiple: 0.50  # layer channel multiple\n","\n","        # anchors\n","        anchors:\n","          - [10,13, 16,30, 33,23]  # P3/8\n","          - [30,61, 62,45, 59,119]  # P4/16\n","          - [116,90, 156,198, 373,326]  # P5/32\n","\n","        # YOLOv5 backbone\n","        backbone:\n","          # [from, number, module, args]\n","          [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","           [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","           [-1, 3, BottleneckCSP, [128]],\n","           [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","           [-1, 9, BottleneckCSP, [256]],\n","           [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","           [-1, 9, BottleneckCSP, [512]],\n","           [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","           [-1, 1, SPP, [1024, [5, 9, 13]]],\n","           [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","          ]\n","\n","        # YOLOv5 head\n","        head:\n","          [[-1, 1, Conv, [512, 1, 1]],\n","           [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","           [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","           [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","           [-1, 1, Conv, [256, 1, 1]],\n","           [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","           [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","           [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","           [-1, 1, Conv, [256, 3, 2]],\n","           [[-1, 14], 1, Concat, [1]],  # cat head P4\n","           [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","           [-1, 1, Conv, [512, 3, 2]],\n","           [[-1, 10], 1, Concat, [1]],  # cat head P5\n","           [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","           [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","          ]\n","        \"\"\"\n","    )"],"metadata":{"id":"LGjHqY0LjgOO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 3: Setup Dataset paths"],"metadata":{"id":"UpE8cKOjHNr6"}},{"cell_type":"code","source":["#@title Setup Dataset Configuration (Data.yaml)\n","train_data_dir = \"/content/yolo_kangaroo/Kangaroo/train\" #@param {type:\"string\"}\n","val_data_dir = \"/content/yolo_kangaroo/Kangaroo/valid\" #@param {type:\"string\"}\n","class_names = ['kangaroo'] #@param {type:\"raw\"}\n","with open('new_data_yaml', 'w+') as file:\n","    file.write(\n","        f\"\"\"\n","        train: {train_data_dir}\n","        val: {val_data_dir}\n","\n","        nc: {number_of_classes}\n","        names: {class_names}\n","        \"\"\"\n","    )"],"metadata":{"id":"3wuviSSijmUq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 4: Start Training"],"metadata":{"id":"w0inZ8cpIyJg"}},{"cell_type":"markdown","source":["**Configuation to try:**\n","\n","*   **Image Size**: 416\n","*   **Batch Size**: 16\n","*   **Epochs**: 200\n","*   **Data Source details** : new_data_yaml (Created earlier)\n","*   **Training details** : new_train_yaml (Created earlier)\n","\n","Example:\n","\n","!python /content/yolov5/train.py --**img** 416 --**batch** 16 --**epochs** 300 --**data** /content/yolov5/new_data_yaml --**cfg** /content/yolov5/new_train_yaml\n"],"metadata":{"id":"5EaomAjuI4Ab"}},{"cell_type":"code","source":["!python /content/yolov5/train.py --img 416 --batch 16 --epochs 200 --data /content/yolov5/new_data_yaml --cfg /content/yolov5/new_train_yaml"],"metadata":{"id":"XYjrtDp-jpyH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 5: Test the trained model on sample images"],"metadata":{"id":"ClPQD4IIKCce"}},{"cell_type":"code","source":["!ls /content/yolov5/runs/train/exp"],"metadata":{"id":"nRF1YxaGj9_d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Inference/Testing**\n","'detect.py' is used to run YOLOv5 testing/inference on different types of inputs such as: image, video, webcam input, directory glob, Youtube, RTSP/RTMP/HTTP Stream.\n","\n","**Usage Syntax:**\n","\n","```shell\n","python detect.py --source 0  # webcam\n","                          img.jpg  # image\n","                          vid.mp4  # video\n","                          path/  # directory\n","                          path/*.jpg  # glob\n","                          'https://youtu.beZgi9g1ksQHc'  # YouTube\n","                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n","                 --weights path/to/weights\n","                 --img 416\n","                 --conf 0.5\n","                 --save-txt\n","```"],"metadata":{"id":"-XE_BpBbXp8p"}},{"cell_type":"code","source":["!python /content/yolov5/detect.py --source '/content/yolo_kangaroo/Kangaroo/valid/images/00010.jpg' --weights '/content/yolov5/runs/train/exp/weights/best.pt' --img 416 --conf 0.5 --save-txt\n","!python /content/yolov5/detect.py --source '/content/yolo_kangaroo/Kangaroo/valid/images/00100.jpg' --weights '/content/yolov5/runs/train/exp/weights/best.pt' --img 416 --conf 0.5 --save-txt\n","!python /content/yolov5/detect.py --source '/content/yolo_kangaroo/Kangaroo/valid/images/00109.jpg' --weights '/content/yolov5/runs/train/exp/weights/best.pt' --img 416 --conf 0.5 --save-txt"],"metadata":{"id":"ooZpypujj9JI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 6: Display result images"],"metadata":{"id":"JuUhFdRfY_-O"}},{"cell_type":"code","source":["import cv2\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed to display the images.\n","%matplotlib inline"],"metadata":{"id":"vFUOsFxTT8N-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = Image.open('/content/yolov5/runs/detect/exp/00010.jpg')\n","plt.imshow(image)"],"metadata":{"id":"ggSen4jYXLdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = Image.open('/content/yolov5/runs/detect/exp2/00100.jpg')\n","plt.imshow(image)"],"metadata":{"id":"ukTT7bdzXYva"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = Image.open('/content/yolov5/runs/detect/exp3/00109.jpg')\n","plt.imshow(image)"],"metadata":{"id":"4Q6C2NA6YtzG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Try on a Youtube video (Optional, takes more time!)"],"metadata":{"id":"PN0GcVTUaQ7w"}},{"cell_type":"code","source":["# Interrupt runtime after 1 min if the video is too long\n","#!python detect.py --source 'https://www.youtube.com/watch?v=wqctLW0Hb_0'\n","!python detect.py --source 'https://youtu.be/KBsqQez-O4w'"],"metadata":{"id":"WjNTdsU2ZJVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert mp4 to webm\n","!ffmpeg -i /content/yolov5/runs/detect/exp7/KBsqQez-O4w.mp4 -vcodec vp9 ./DetectionResult.webm"],"metadata":{"id":"StVVfnJvfmqw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the Result!!\n","import io\n","from base64 import b64encode\n","from IPython.display import HTML\n","\n","with  io.open('/content/yolov5/DetectionResult.webm','r+b') as f:\n","    mp4 = f.read()\n","data_url = \"data:video/webm;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/webm\">\n","</video>\n","\"\"\" % data_url)"],"metadata":{"id":"4BWc_ff-fJlF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 7: Display performance analysis"],"metadata":{"id":"ASzqmy_GAXxt"}},{"cell_type":"markdown","source":["Training results are automatically logged to Tensorboard and CSV as `results.csv`, which is plotted as `results.png` (below) after training completes. You can also plot any `results.csv` file manually:"],"metadata":{"id":"z79oz5iPbUqB"}},{"cell_type":"code","source":["image = Image.open('/content/yolov5/runs/train/exp/results.png') # Change 'exp' to the last in the train directory\n","plt.imshow(image)"],"metadata":{"id":"b4xEYywVFB8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#[OPTIONAL] Alternate way of ploting the curves from CSV file\n","from utils.plots import plot_results\n","# Change the path to the last exp under train folder.\n","plot_results('/content/yolov5/runs/train/exp/results.csv')  # plot 'results.csv' as 'results.png'"],"metadata":{"id":"xrwRiD1RAqEJ"},"execution_count":null,"outputs":[]}]}